{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Search Quest for Spotity Track popularity regression model\n",
    "\n",
    "Using the great analysis code by CEF we will first perform a RandomGridSearch on diffent models and parameters. Based on the results the best model will be selected and we will perform a more extensive GridSearch for the optimal hyperpameters to define the best model for predicting the popularity feature of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# sys.path.append(\"../include/\")\n",
    "basePath = os.getcwd()\n",
    "basePath = os.path.split(basePath)[0]\n",
    "basePath = os.path.split(basePath)[0]\n",
    "sys.path.append(os.path.join(basePath, \"include\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# credit to CEF with modification\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "from libitmal import dataloaders_v3 as itmaldataloaders\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "data_csv_path = basePath + \"/Slutprojekt/csv/spotifyDBData_preprocessed_onehotenc.csv\"\n",
    "spotifyDBData = pd.read_csv(data_csv_path, sep=',', header=0)\n",
    "input_features = [\n",
    "#     \"popularity\",\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"tempo\",\n",
    "    \"valence\",\n",
    "    \"genre_alternative\",\n",
    "    \"genre_anime\",\n",
    "    \"genre_blues\",\n",
    "    \"genre_childrens-music\",\n",
    "    \"genre_classical\",\n",
    "    \"genre_comedy\",\n",
    "    \"genre_country\",\n",
    "    \"genre_dance\",\n",
    "    \"genre_electronic\",\n",
    "    \"genre_folk\",\n",
    "    \"genre_hip-hop\",\n",
    "    \"genre_indie\",\n",
    "    \"genre_jazz\",\n",
    "    \"genre_movie\",\n",
    "    \"genre_opera\",\n",
    "    \"genre_pop\",\n",
    "    \"genre_rnb\",\n",
    "    \"genre_rap\",\n",
    "    \"genre_reggae\",\n",
    "    \"genre_reggaeton\",\n",
    "    \"genre_rock\",\n",
    "    \"genre_ska\",\n",
    "    \"genre_soul\",\n",
    "    \"genre_soundtrack\",\n",
    "    \"genre_world\",\n",
    "    \"mode_major\",\n",
    "    \"mode_minor\",\n",
    "    \"time_signature_3-4\",\n",
    "    \"time_signature_4-4\",\n",
    "    \"time_signature_5-4\"\n",
    "]\n",
    "\n",
    "def getSpotifyBinarizedXY():\n",
    "    X = np.array(spotifyDBData[input_features])\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    # lb.fit(np.array(spotifyDBData['genre']))\n",
    "    y = lb.fit_transform(np.array(spotifyDBData['genre']))\n",
    "\n",
    "    print(\"Binarized Label to the following classes\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def getSpotifyIntLabeledXY():\n",
    "    X = np.array(spotifyDBData[input_features])\n",
    "\n",
    "    label_encoder = LabelEncoder() \n",
    "    y = spotifyDBData['popularity']\n",
    "    # print(y.unique())\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "#%%\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            r=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                t = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(r)>0:\n",
    "                    r += ','\n",
    "                r += f'{key}={t}{value}{t}'  \n",
    "            return r            \n",
    "        try:\n",
    "            p = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + p + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "#     assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    #ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(fetchmode=False)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    elif mode=='spotify_binarized':\n",
    "        X, y = getSpotifyBinarizedXY()\n",
    "    elif mode=='spotify_intlabels':\n",
    "        X, y = getSpotifyIntLabeledXY()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}'\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    # assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: spotify_intlabels..\n",
      "  org. data:  X.shape      =(222593;   39), y.shape      =(222593)\n",
      "  train data: X_train.shape=(155815;   39), y_train.shape=(155815)\n",
      "  test data:  X_test.shape =(66778;   39), y_test.shape =(66778)\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    3.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    4.8s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 6.35 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'solver': 'svd', 'normalize': False, 'fit_intercept': True}\n",
      "\tbest 'r2' score=0.6628795040449617\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='svd', tol=0.001)\n",
      "\n",
      "Grid scores ('r2') on development set:\n",
      "\t[ 0]: 0.663 (+/-0.005) for {'solver': 'cholesky', 'normalize': False, 'fit_intercept': True}\n",
      "\t[ 1]: 0.662 (+/-0.005) for {'solver': 'sparse_cg', 'normalize': False, 'fit_intercept': False}\n",
      "\t[ 2]: 0.663 (+/-0.005) for {'solver': 'svd', 'normalize': False, 'fit_intercept': True}\n",
      "\t[ 3]: 0.663 (+/-0.005) for {'solver': 'auto', 'normalize': False, 'fit_intercept': False}\n",
      "\t[ 4]: 0.535 (+/-0.003) for {'solver': 'auto', 'normalize': True, 'fit_intercept': True}\n",
      "\t[ 5]: 0.663 (+/-0.005) for {'solver': 'sag', 'normalize': False, 'fit_intercept': True}\n",
      "\t[ 6]: 0.663 (+/-0.005) for {'solver': 'lsqr', 'normalize': True, 'fit_intercept': False}\n",
      "\t[ 7]: 0.663 (+/-0.005) for {'solver': 'svd', 'normalize': False, 'fit_intercept': False}\n",
      "CTOR for best model: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='svd', tol=0.001)\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.66288, model=Ridge(fit_intercept=True,normalize=False,solver='svd')\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.66288, model=Ridge(fit_intercept=True,normalize=False,solver='svd')\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    1.7s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    2.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 2.15 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'precompute': True, 'normalize': True, 'fit_intercept': True}\n",
      "\tbest 'r2' score=-2.5560023697490665e-05\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tLasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=True, positive=False, precompute=True, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Grid scores ('r2') on development set:\n",
      "\t[ 0]: -0.000 (+/-0.000) for {'precompute': True, 'normalize': True, 'fit_intercept': True}\n",
      "\t[ 1]: -0.000 (+/-0.000) for {'precompute': False, 'normalize': True, 'fit_intercept': True}\n",
      "\t[ 2]: -0.000 (+/-0.000) for {'precompute': True, 'normalize': False, 'fit_intercept': True}\n",
      "\t[ 3]: -0.000 (+/-0.000) for {'precompute': False, 'normalize': False, 'fit_intercept': True}\n",
      "\t[ 4]: -6.458 (+/-0.114) for {'precompute': True, 'normalize': True, 'fit_intercept': False}\n",
      "\t[ 5]: -6.458 (+/-0.114) for {'precompute': False, 'normalize': True, 'fit_intercept': False}\n",
      "\t[ 6]: -6.458 (+/-0.114) for {'precompute': True, 'normalize': False, 'fit_intercept': False}\n",
      "\t[ 7]: -6.458 (+/-0.114) for {'precompute': False, 'normalize': False, 'fit_intercept': False}\n",
      "CTOR for best model: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=True, positive=False, precompute=True, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "best: dat=spotify_intlabels, score=-0.00003, model=Lasso(fit_intercept=True,normalize=True,precompute=True)\n",
      "\n",
      "best: dat=spotify_intlabels, score=-0.00003, model=Lasso(fit_intercept=True,normalize=True,precompute=True)\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    1.8s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    1.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.2s finished\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 2.45 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'penalty': 'l1', 'loss': 'epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0013}\n",
      "\tbest 'r2' score=0.658702545001534\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDRegressor(alpha=0.0013, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "       max_iter=None, n_iter=None, n_iter_no_change=5, penalty='l1',\n",
      "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "Grid scores ('r2') on development set:\n",
      "\t[ 0]: 0.655 (+/-0.008) for {'penalty': 'l2', 'loss': 'epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0003}\n",
      "\t[ 1]: 0.546 (+/-0.005) for {'penalty': 'l1', 'loss': 'squared_epsilon_insensitive', 'fit_intercept': False, 'alpha': 0.0013}\n",
      "\t[ 2]: 0.659 (+/-0.006) for {'penalty': 'l1', 'loss': 'epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0013}\n",
      "\t[ 3]: 0.654 (+/-0.004) for {'penalty': 'l2', 'loss': 'huber', 'fit_intercept': False, 'alpha': 0.0009}\n",
      "\t[ 4]: 0.637 (+/-0.006) for {'penalty': 'elasticnet', 'loss': 'squared_epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0013}\n",
      "\t[ 5]: 0.643 (+/-0.007) for {'penalty': 'none', 'loss': 'squared_epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0006}\n",
      "\t[ 6]: 0.642 (+/-0.009) for {'penalty': 'none', 'loss': 'squared_epsilon_insensitive', 'fit_intercept': True, 'alpha': 0.0009}\n",
      "\t[ 7]: 0.649 (+/-0.005) for {'penalty': 'elasticnet', 'loss': 'huber', 'fit_intercept': False, 'alpha': 0.0012}\n",
      "CTOR for best model: SGDRegressor(alpha=0.0013, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "       max_iter=None, n_iter=None, n_iter_no_change=5, penalty='l1',\n",
      "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.65870, model=SGDRegressor(alpha=0.0013,fit_intercept=True,loss='epsilon_insensitive',penalty='l1')\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.65870, model=SGDRegressor(alpha=0.0013,fit_intercept=True,loss='epsilon_insensitive',penalty='l1')\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    6.1s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    6.5s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 42.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 42.3min finished\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 2538.98 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'shrinking': True, 'kernel': 'rbf', 'epsilon': 0.4, 'degree': 11}\n",
      "\tbest 'r2' score=0.20627145276483255\n",
      "\tbest index=4\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVR(C=1.0, cache_size=200, coef0=0.0, degree=11, epsilon=0.4,\n",
      "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Grid scores ('r2') on development set:\n",
      "\t[ 0]: -0.218 (+/-0.007) for {'shrinking': True, 'kernel': 'poly', 'epsilon': 0.8, 'degree': 31}\n",
      "\t[ 1]: -47.775 (+/-1.193) for {'shrinking': False, 'kernel': 'sigmoid', 'epsilon': 0.1, 'degree': 35}\n",
      "\t[ 2]: -0.218 (+/-0.007) for {'shrinking': True, 'kernel': 'rbf', 'epsilon': 0.7, 'degree': 8}\n",
      "\t[ 3]: -0.218 (+/-0.007) for {'shrinking': True, 'kernel': 'poly', 'epsilon': 1.0, 'degree': 12}\n",
      "\t[ 4]: 0.206 (+/-0.024) for {'shrinking': True, 'kernel': 'rbf', 'epsilon': 0.4, 'degree': 11}\n",
      "\t[ 5]: -0.218 (+/-0.007) for {'shrinking': False, 'kernel': 'poly', 'epsilon': 1.0, 'degree': 10}\n",
      "\t[ 6]: -0.218 (+/-0.007) for {'shrinking': True, 'kernel': 'linear', 'epsilon': 0.8, 'degree': 37}\n",
      "\t[ 7]: -0.218 (+/-0.007) for {'shrinking': True, 'kernel': 'linear', 'epsilon': 1.0, 'degree': 30}\n",
      "CTOR for best model: SVR(C=1.0, cache_size=200, coef0=0.0, degree=11, epsilon=0.4,\n",
      "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.20627, model=SVR(degree=11,epsilon=0.4,kernel='rbf',shrinking=True)\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.20627, model=SVR(degree=11,epsilon=0.4,kernel='rbf',shrinking=True)\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 6 is smaller than n_iter=8. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.8s\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    8.6s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 64.1min remaining: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 75.8min remaining:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 92.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 5551.12 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'splitter': 'best', 'criterion': 'friedman_mse'}\n",
      "\tbest 'r2' score=0.37571718673599874\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tDecisionTreeRegressor(criterion='friedman_mse', max_depth=None,\n",
      "           max_features=None, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')\n",
      "\n",
      "Grid scores ('r2') on development set:\n",
      "\t[ 0]: 0.374 (+/-0.020) for {'splitter': 'best', 'criterion': 'mse'}\n",
      "\t[ 1]: 0.369 (+/-0.017) for {'splitter': 'random', 'criterion': 'mse'}\n",
      "\t[ 2]: 0.376 (+/-0.019) for {'splitter': 'best', 'criterion': 'friedman_mse'}\n",
      "\t[ 3]: 0.369 (+/-0.014) for {'splitter': 'random', 'criterion': 'friedman_mse'}\n",
      "\t[ 4]: 0.372 (+/-0.012) for {'splitter': 'best', 'criterion': 'mae'}\n",
      "\t[ 5]: 0.365 (+/-0.014) for {'splitter': 'random', 'criterion': 'mae'}\n",
      "CTOR for best model: DecisionTreeRegressor(criterion='friedman_mse', max_depth=None,\n",
      "           max_features=None, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.37572, model=DecisionTreeRegressor(criterion='friedman_mse',splitter='best')\n",
      "\n",
      "best: dat=spotify_intlabels, score=0.37572, model=DecisionTreeRegressor(criterion='friedman_mse',splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, LogisticRegression, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# TODO: Qd..(in code and text..)\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('spotify_intlabels') # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "search_space = [ \n",
    "    (Ridge(), {\n",
    "        'fit_intercept': (True, False),\n",
    "        'normalize':(True, False),\n",
    "        'solver' : ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga')\n",
    "    }),\n",
    "#     (Lasso(), {\n",
    "#         'fit_intercept': (True, False),\n",
    "#         'normalize':(True, False),\n",
    "#         'precompute': (True, False)    \n",
    "#     }),\n",
    "    (SGDRegressor(), {\n",
    "        'loss': ('squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'),\n",
    "        'penalty': ('none', 'l2', 'l1', 'elasticnet'),\n",
    "        'alpha':[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015],\n",
    "        'fit_intercept': (True, False),\n",
    "    }),\n",
    "#     (SVR(), {\n",
    "#         'kernel': ('rbf', 'linear', 'poly', 'sigmoid', 'precomputed'),\n",
    "#         'degree': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "#                   21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39),\n",
    "#         'epsilon': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0),\n",
    "#         'shrinking': (True, False)\n",
    "#     }),\n",
    "#     (\n",
    "#     KNeighborsRegressor(n_jobs=-1), {\n",
    "#     'n_neighbors':[3,4,5],\n",
    "#     'weights':('uniform', 'distance'),\n",
    "#     'algorithm':('ball_tree', 'kd_tree', 'brute'),\n",
    "#     'p':[2,3,4],    \n",
    "#     }),\n",
    "#     (GaussianProcessRegressor(), {\n",
    "#         'kernal': ('rbf', 'linear', 'poly', 'sigmoid', 'precomputed')\n",
    "#         'degree': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "#                   21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39),\n",
    "#         'epsilon': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0),\n",
    "#         'shrinking': (True, False)\n",
    "#     }),\n",
    "#     (DecisionTreeRegressor(), {\n",
    "#     'criterion' : ('mse', 'friedman_mse', 'mae'),\n",
    "#     'splitter' : ('best', 'random'),  \n",
    "#     })\n",
    "]\n",
    "\n",
    "\n",
    "CV=5\n",
    "VERBOSE=0\n",
    "\n",
    "for model, tuning_parameters in search_space:\n",
    "# Run Randomized Search - RandomizedSearchCV for the model\n",
    "    start = time()\n",
    "    random_tuned = RandomizedSearchCV(\n",
    "        model, \n",
    "        tuning_parameters, \n",
    "        random_state=42, \n",
    "        n_iter=8, \n",
    "        cv=CV, \n",
    "        scoring='r2', \n",
    "        verbose=10, \n",
    "        n_jobs=-1, \n",
    "        iid=True)\n",
    "    random_tuned.fit(X_train, y_train)\n",
    "    t = time()-start\n",
    "\n",
    "    # Report result\n",
    "    b0, m0= FullReport(random_tuned , X_test, y_test, t)\n",
    "    print(b0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1ead28bdc468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(X_test[200].reshape(1, -1)))\n",
    "print(y_test[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}