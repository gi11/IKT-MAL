{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supergruppe diskussion\n",
    "\n",
    "## § 2 \"End-to-End Machine Learning Project\" [HOML]\n",
    "\n",
    "Genlæs kapitel (eksklusiv\"Create the Workspace\" og \"Download the Data\"), og forbered mundtlig præsentation.\n",
    "\n",
    "Lav et kort resume af de enkelte underafsnit, ca. 5 til 20 liners tekst.\n",
    "\n",
    "Husk at relater til \"The Map\":\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/E19_itmal/L07/Figs/ml_supervised_map.png\" style=\"width:400px\">\n",
    "\n",
    "Kapitler (incl. underkapitler):\n",
    "\n",
    "* Look at the Big Picture\n",
    "* Get the Data (eksklusiv Create the Workspace og Download the Data),\n",
    "* Discover and Visualize the Data to Gain Insights,\n",
    "* Prepare the Data for Machine Learning Algorithms,\n",
    "* Select and Train a Model,\n",
    "* Fine-Tune Your Model,\n",
    "* Launch, Monitor, and Maintain Your System,\n",
    "* Try It Out!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume: Look at the Big Picture\n",
    "\n",
    "- Hvad er problemet - e.g hvad er det helt præcist der skal løses. Bogens eksempel - forudse huspriser baseret på deres lokation(districts)(Bogens udgangspunkt et output der bruges i en anden algorithme).\n",
    "- Har vi noget at sammenligne med? Præcission, omkostninger osv..\n",
    "- Hvordan løses det, hvilken type problem har vi? Supervised, unsupervised, regression eller klassifikation?\n",
    "    - Bogen: Unsupervised, hvorfor(labelled dataset)? Regression, hvorfor?(Finde sammenhæng mellem lokation og pris)\n",
    "    - Eget: Klassifikation af genre baseret på andre features defineret på musik.\n",
    "- Bestem en performance measure (cost funktion). Hvad er det helt præcist denne fortæller os?\n",
    "    - Hvilke kender vi? RMSE(l2), MSE(l1). Standard vektor afstande(l2 = norm). \n",
    "- Husk at reflekter over ovenstående - flere valg. Hvad er formålet, det er ikke nødtvendigt at arbejde på en meget præcis regressionsmodel, hvis huspriser (kapitlets eksempel) senere skal opdeæes efter kategorier.\n",
    "\n",
    "#### Resume: Get the Data (eksklusiv Create the Workspace og Download the Data)\n",
    "\n",
    "- Check data, hvilke features indeholder disse? Herunder metoder hertil, e.g(pandas) .head(), .info() og .describe() - fra sidste kan vi bla. se $\\sigma$ og $\\sigma^2$, samt featuresne numeriske størrelser(counts), procentiler, min og max.\n",
    "    - Ovenstående kan visualiseres ved histogrammer(matplotlib). \n",
    "- Er noget af dataen blevet præprocesseret, i så fald er det noget vi skal forholde os til?\n",
    "    - Det kan evt. være der skal indsamles ny data for de eksisterende samples\n",
    "    - Eller at dette de påvirkede data fjernes fra sættet, sådan modellen ikke bliver påvirket til en bias.\n",
    "    \n",
    "    - Vi har måske behov for at gøre dette på eget datasæt, da mange \"track\" ikke er blevet kategorieret efter popularitet endnu.\n",
    "    \n",
    "- Opdel data i train/test set - ROT, 20% test. Hvorfor? Undgå \" _data Snooping Bias_ \" (At vi deteketere patterns som leder til beslutning om en specifik model til netop dette - overfitting). Ydermere programspecifikke metode til at splitte data, train_test_split(). \n",
    "    - Vær forsigt med hvordan dataen opdeles, hvis modellen trænes over flere runs, og trænningssætet er blevet randomized på index vil modellen over tid blive trænet på en større del af datasættet, vi ønsker at den skal set testsættet før, før vi er klar til den endelige valideringen. - Der metoder til at forhindre dette udfald (hashing af identifier).\n",
    "\n",
    "    - \" _Stratified Sampling_ \" Dataen skal være repræsentativ for gruppen det er taget fra. Sørg for at test sættet indeholder samme fordeling som det originale dataset. Bogen bruger en metode med .cut(). Stratisfied sampling tillader et test sæt der er mindre skewed end det ved random sampling, måles fordeling i forhold til det originale dataset(mere repræsentativt). Statisfied sampling kan udføres ved brug af StratisfiedShuffleSplit() klassen. \n",
    "\n",
    "#### Resume: Discover and Visualize the Data to Gain Insights,\n",
    "\n",
    "- Visualisering af data - generer plots til at hjælpe med at gennemskue sammenhæng. E.g i bogen hvor der genereres et scatter ud fra distriktets koordinater. Husk, district er en samling af mennesker hvis hus der er data for, altså forventes høj densitet af distrikter i byer! \n",
    "    - Brug farver og transperans til at yderligere synliggør både tæthed og værdier(bogen, transparans til tæthed, farve til house_val).\n",
    "- Correlation, som fra statistik. Correlation i eksemplet vil da svare til kryds, hvortil det vi får ud er hvor meget signalerne \"minder\" om hianden, eller nærmere, findes der en sammenhæng? Scatter matrix er fed, svare til \"korrelations matrix\", e.g på diagonalen findes auto corr, og kryds uden for - hurtigt overblik. \n",
    "    - Visualisering kan hjælpe med både at finde sammenhænge i data, men også underliggende sammenhænge som kan ønskes fra sorteret - i bogens eksempel, \"median_house_value\" lofter for distrikter. \n",
    "- Sidst, attributter(features) kan kombineres i håb om en højere correlation. I bogens eksempel findes der en god sammenhæng mellem antallet af soveværelser pr værelse og husets værdi. DF's gør det nemt at genere kombinerede features(bogens eksempel). \n",
    "\n",
    "#### Resume: Prepare the Data for Machine Learning Algorithms\n",
    "- Data cleaning and feature scaling - Dataen skal forberede, således at den kan \"feedes\" til den valgte model. De fleste algoritmer har svært ved at håndtere null-data og og data med stor skaleringsforskel på nummeriske data.\n",
    "    - Data cleaning, 3 muligheder\n",
    "            - Vi kan fjerne samples der har null data \n",
    "            - Fjerne attributes fra alle samples helt\n",
    "            - Fylde manglende værdier, evt. med middelværdier.\n",
    "    \n",
    "    - Feature Scaling: Normalisering og standardisering af data, standardiseringen er mindre følsom overfor outliers (eksempel ved fejl i housing data: median income : 100 -> 1 values 0-15 -> 0.15 - ved normalisreing).\n",
    "    \n",
    "    - Datakategorier (one-hot encoding): At inddrage features bestående af forskellige kategorier kan  være besværligt da disse skal kunne konverteres til nummeriske værdier og afhængig af featuren beskriver afstanden mellem disse katogorier mere eller mindre godt. - Løsingen er one-hot encoding at skabe en binær feature for hver kategori.\n",
    "    \n",
    "    - Automate transformation (Transformation pipeline): Pipelines kan hjælpe med at automatisere forberedelsesprocessen af data, sådan denne kan udføres på nye datasæt, nye data i det nuværende sæt vurdere de feature engineering valg.\n",
    "\n",
    "#### Resume: Select and Train a Model\n",
    "- Focus is on choosing the correct model, but how does one go about? Remember, the performance measure is our reference! Things to take into consideration when training and measuring the model: \n",
    "    - Overfitting\n",
    "    - Underfitting\n",
    "- The above can be hard to determine unless you are in an outer case(horrible or perfect performance measure of model). So, what can one do to help deciding on a good model? \n",
    "    - Cross validation. Again, uses the idea to split dataset into train/test. Doing this 10 times, providing performance meassure for each validation. \n",
    "        - Makes it easier to determine a poorly choosen model! \n",
    "- Lastly, computation time is to be considered as well. Do NOT discard results of models, as the dataset can be big, having to reperform validations and trainings can be time consuming! Time is money friend. \n",
    "\n",
    "\n",
    "#### Resume: Fine-Tune Your Model\n",
    "- When a short list of fitting models is selected its time to optimize the hyper parameters. This too can be automated using algorithms to train and crossvalidate the model using all possible combinations of defined set of parameters.\n",
    "     - RandomizedGridSearchCV: This algoritm tries random hyper parameters and returns their performance. -Helping you narrow in on the best params for your selected model.\n",
    "     - GridSearchCV: This algoritm tries out all possible combinations of a set of hyperparameters you predefined.\n",
    "         - Better for a small set of combinaton options.\n",
    "         - ParamGrid: Dictionary of key-list pairs defining paramters and combination options\n",
    " \n",
    "\n",
    "#### Resume: Launch, Monitor, and Maintain Your System\n",
    "- For a real ML application its not over when a good model is reached. It's when the model has to be launched and then maintained. Systems have to be created to:\n",
    "     - Monitor live performance regularly and trigger alerts if it drops. \n",
    "     - Montoring often also require human analysis of prediction samples\n",
    "     - Input data has to evaluated as model generally tend to rot over time.\n",
    "     - Retrain your model using fresh data, as the input data changes over time\n",
    "     \n",
    "#### Resume: Try It Out!.\n",
    "- This section is a summary of the entire chapter and a call to action for us to apply the techniques to our own dataset.\n",
    "\n",
    "    - In our case with the spotity data, were primarily focused on a classification task: a model that can predict a musical number's genre based on other feature, presumably we are going to use supervised learning.\n",
    "    - We already have a dataset from Kaggle  containing around 233.0000 songs,( ~ 10000 per 26 unique genres), each with 16 features. - This is our preliminary analysis, and we need to analyze further.\n",
    "    - We need to test different models and the create a pipeline that will test different hyper parameters. Then we might also need a transformation pipeline to clean the data, as the dataset is a bit skewed since it do contain a number of tracks not yet categorised according to populariy. - We probably should not use mean values to fill this out, but is our sample set big enough if we drop all the tracks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
