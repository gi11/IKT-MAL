<!DOCTYPE html>
<html>
<head>
<title>L05.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<h1 id="itmal-%C3%B8velser---uge-5">ITMAL Øvelser - Uge 5</h1>
<ul>
<li><a href="#itmal-%c3%98velser---uge-5">ITMAL Øvelser - Uge 5</a>
<ul>
<li><a href="#%c3%98velse-1">Øvelse 1</a>
<ul>
<li><a href="#a">a)</a></li>
<li><a href="#b">b)</a></li>
<li><a href="#c">c)</a></li>
<li><a href="#d">d)</a></li>
<li><a href="#e">e)</a></li>
</ul>
</li>
<li><a href="#%c3%98velse-2">Øvelse 2</a></li>
</ul>
</li>
</ul>
<h2 id="%C3%B8velse-1">Øvelse 1</h2>
<p>For this subexercise the group is to perform data analysis of the given dataset, namely &quot;california housing prices&quot;. The subexercise consists of 5 parts which will be described herafter in chronological order. Before starting, the group needs to get the data read in the python workspace, to which is has been decided to store it as a pandas dataframe. This is done as pandas is build on numpy, and as such, has the same features as numpy with more.</p>
<pre class="hljs"><code><div>    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
    <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
    <span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> norm
    <span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
    <span class="hljs-keyword">import</span> math

    <span class="hljs-comment"># Load data - vægt data (kvinder/mænd)</span>
    data = pd.read_csv(<span class="hljs-string">'.../Uge5_files/housing.csv'</span>, sep=<span class="hljs-string">','</span>,header=<span class="hljs-number">0</span>)
</div></code></pre>
<h3 id="a">a)</h3>
<p>For the first part we are to plot the distribution of the median_income data for the districts. This is done using matplotlibs <em>hist()</em> function. Futhermore, mean, variance, std. deviatien and median can all be found using numpy's build in methods.</p>
<pre class="hljs"><code><div>    median_income = data[<span class="hljs-string">'median_income'</span>] <span class="hljs-comment"># Extract column of df</span>

    mu = np.mean(median_income)         <span class="hljs-comment"># Mean</span>
    sigma = np.std(median_income)       <span class="hljs-comment"># Var</span>
    sigma2 = np.var(median_income)      <span class="hljs-comment"># std deviatien</span>
    median = np.median(median_income)   <span class="hljs-comment"># Median</span>
    print(<span class="hljs-string">f"Mean: <span class="hljs-subst">{mu}</span>, Varians <span class="hljs-subst">{sigma2}</span>, Std Deviatien <span class="hljs-subst">{sigma}</span>, Median <span class="hljs-subst">{median}</span>"</span>)
</div></code></pre>
<p>Yields:</p>
<pre><code>Mean: 3.8706710029070246, Varians 3.60914768969746, Std Deviatien 1.899775694574878, Median 3.5347999999999997
</code></pre>
<p>With the plot using matplotlib:</p>
<pre class="hljs"><code><div>fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, figsize=[<span class="hljs-number">8</span>,<span class="hljs-number">8</span>])   <span class="hljs-comment"># Create the plot object</span>
ax.hist(median_income,bins=<span class="hljs-number">100</span>, density=<span class="hljs-literal">True</span>) <span class="hljs-comment"># Normalises the histogram</span>
</div></code></pre>
<figure class="image">
    <img src=fig/California_Housing_dist.png>
    <figcaption> <center> Median income distribution from california housing prices </figcaption> 
</figure>
<p>From the above it is seen that the histogram somewhat resembles a normal distribution, although it must be noted that is rather tail heavy towards the higher median income values. Futhermore, it is noted that there is a rather large amount of districts towards the right with a extremely high median income - this and the heavy tail could explain the skewedness in the mean value compared to the median.</p>
<h3 id="b">b)</h3>
<p>Now, looking at the mean and medianb, it is seen these are not identical. This is easily explained if &quot;median_income&quot; is seen as a column vector, where the mean is exactly the sum of all it's values, divided by it's length. The median however, is the value of the center index in the vector. So, which is the most telling? In the case of median income, the mean can be quite biased, as this is more easily influenced by outliers - for example the mean income of the population of a country might be heavily influenced by the top 1%, and therefore not very telling of the average citizen. The same goes for our example.</p>
<h3 id="c">c)</h3>
<p>For this part, a true normal distribution is fitted on top of the histogram - since we already normalised the histogram, this should be directly comparable:</p>
<pre class="hljs"><code><div>    myMax = np.max(median_income)
    myMin = np.min(median_income)
    xarr = np.linspace(myMax, myMin, <span class="hljs-number">500</span>)    
    ax.plot(xarr, norm.pdf(xarr, mu, sigma)) <span class="hljs-comment"># Plot</span>
</div></code></pre>
<p>Which yields the plot:</p>
<figure class="image">
    <img src=fig/California_Housing_dist2.png>
    <figcaption> <center> Median income distribution from california housin prices, now with a true normal distribution on top </figcaption> 
</figure>
<p>From which it is seen that our distribution does not follow that of a normal distribution, as it is too tail heavy, and as such, has shifted it's mean too far to the right. Furthermore, it would seem that our variance is also affected by the tail heavyness, as the true gaussian model does not encapsulate(reach) our top points around the median or mean.</p>
<h3 id="d">d)</h3>
<p>In order to determine if there is a correlation between median house value, and median income, this is computed and plotted:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Check if there is a corelation between median income and median house value</span>
medIncAndHVal = data[[<span class="hljs-string">'median_income'</span>,<span class="hljs-string">'median_house_value'</span>]]
corrcoef = np.corrcoef(medIncAndHVal.T) <span class="hljs-comment"># obs: rækker=variable, kolonner=samples (modsat normalt..)</span>

plt.scatter(medIncAndHVal[<span class="hljs-string">'median_income'</span>], medIncAndHVal[<span class="hljs-string">'median_house_value'</span>], s=<span class="hljs-number">1</span>)
    
plt.title(<span class="hljs-string">f"p: <span class="hljs-subst">{corrcoef[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]}</span>"</span>)
plt.xlabel(<span class="hljs-string">'Median Income'</span>)
plt.ylabel(<span class="hljs-string">'Median House Value'</span>)
</div></code></pre>
<p>Which yields:</p>
<figure class="image">
    <img src=fig/Corr_plot.png>
    <figcaption> <center> Correlation plot of median house value and income </figcaption> 
</figure>
<p>From the above, a trend can be seen along the axis' as they seem to be increasing together(a linear upward trend, or positive correlation). The correlation coefficient(title of plot) verifies this. At the same time, some vague horisontal lines can be seen. These seem to limitations in the house value, which must stem from an unknown bias(or prerendition) of the data we are processing. The upmost horizontol line of the data plots seem to stem from an upper limit on the measurement collecting the data.</p>
<h3 id="e">e)</h3>
<p>For this part, the 5% and 95% percentile is to be found. This is done using numpy's build in functions like before:</p>
<pre class="hljs"><code><div>print(<span class="hljs-string">"Fifth Percentile of med H val: "</span>, np.percentile(data[<span class="hljs-string">'median_house_value'</span>], <span class="hljs-number">5</span>))

print(<span class="hljs-string">"Ninety-fith Percentile of H val: "</span>, np.percentile(data[<span class="hljs-string">'median_house_value'</span>], <span class="hljs-number">95</span>))

print(<span class="hljs-string">"With max: "</span>, np.max(data[<span class="hljs-string">'median_house_value'</span>]), <span class="hljs-string">" and Min: "</span>, np.min(data[<span class="hljs-string">'median_house_value'</span>]))
</div></code></pre>
<p>Which yields:</p>
<pre class="hljs"><code><div>Fifth Percentile of med H val:  66200.0
Ninety-fith Percentile of H val:  489809.9999999998
With max:  500001.0  and Min:  14999.0
</div></code></pre>
<p>Telling us that 5% of the districts has a median income of 66200 or less, and 95% has a median income of 489809 or less.</p>
<p>Using the same code as before, but with another feature from the dataset, median house value, a distribution can be found:</p>
<figure class="image">
    <img src=fig/Median_house_value.png>
    <figcaption> <center> Median house value histogram </figcaption> 
</figure>
<p>From the above, an obvious fault can be seen(the reason for the horizontol line before) at a median house value of 500000. Like said, this must stem from the data not being able to measure past this value, and as such, this value cannot be seen as representative, as these values can range from 500000 to $\infty$. A solution to this could be to remove all districts with this value, or simply assign them the median instead. Looking at the representation, e.g the numbers of samples with this value, the first seems the best, as the other would assign an artificial bias to the set. Also, disregarding the top value, the distribution does not seem to follow that of a gausian one, as this is heavily tail heavy towards the upper values - it seems more to resemble that of a Reyleigh distribution if one were to guess.</p>
<h2 id="%C3%B8velse-2">Øvelse 2</h2>
<p>The group has chosen a dataset based on data collected from spotifys API, containing information about songs on the platform. Each song is described by 16 features:</p>
<ul>
<li>Genre</li>
<li>Artist name</li>
<li>Track name</li>
<li>Track ID</li>
<li>Popularity</li>
</ul>
<p>The remaining 11 features are 'audio features' which describe different aspects of the tracks <em><strong>sound</strong></em> and <em><strong>feel</strong></em>. These are</p>
<ul>
<li>Acousticness</li>
<li>Danceability</li>
<li>Duration in ms</li>
<li>Energy</li>
<li>Instrumentalness</li>
<li>Key</li>
<li>Liveness</li>
<li>Loudness</li>
<li>Mode</li>
<li>Speechiness</li>
<li>Tempo</li>
<li>Time signature</li>
<li>Valence</li>
</ul>
<p>The group wishes to investigate the relationship, correlations, etc, between these audiofeatures, genre and popularity.</p>
<h3 id="importing-the-data">Importing the data</h3>
<p>The data is loaded from the csv file into a pandas dataframe</p>
<pre class="hljs"><code><div>data_csv_path = <span class="hljs-string">"path/to/SpotifyFeatures.csv"</span>
spotifyDBData = pd.read_csv(data_csv_path, sep=<span class="hljs-string">','</span>, header=<span class="hljs-number">0</span>)
</div></code></pre>
<p>Now we can investigate the distibution of the different features in the dataset</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Lets look at popularity and see if it follows a normal distribution</span>
trackPopularity = spotifyDBData[<span class="hljs-string">'popularity'</span>]

<span class="hljs-comment"># Find the statistical properties of the popularity</span>
mu = np.mean(trackPopularity)
sigma = np.std(trackPopularity)
sigma2 = np.var(trackPopularity)
median = np.median(trackPopularity)

<span class="hljs-comment"># Create an object to plot into</span>
fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, figsize=[<span class="hljs-number">10</span>,<span class="hljs-number">6</span>])

<span class="hljs-comment"># Plot the popularity data to get an idea of it's distribution</span>
ax.hist(trackPopularity,bins=<span class="hljs-number">100</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">'Track Popularity'</span>) <span class="hljs-comment"># Histogram is normalized</span>
plt.xlabel(<span class="hljs-string">'Popularity rating'</span>)
plt.ylabel(<span class="hljs-string">'Normalised Counts'</span>)
ax.axvline(mu, color=<span class="hljs-string">'b'</span>, label = <span class="hljs-string">"Mean"</span>)
ax.axvline(median, color=<span class="hljs-string">'r'</span>, label=<span class="hljs-string">"Median"</span>)

<span class="hljs-comment"># Try and fit a gausian distribution</span>
xarr = np.linspace(np.max(trackPopularity), np.min(trackPopularity), <span class="hljs-number">500</span>)
ax.plot(xarr, norm.pdf(xarr, mu, sigma), label=<span class="hljs-string">'True gausian PDF'</span>)
ax.legend()
</div></code></pre>
<p>Running this results in the following output:</p>
<figure class="image">
    <img src=fig/popularity_hist.png>
    <figcaption> <center> Popularity histogram </figcaption> 
</figure>
<p>It can be seen that the distribution resembles a normal distribution, but deviates significantly in some places. The most notable difference being the big spike in the first bin, which could have several explanations. It might be that there are simply just a lot of unpopular songs on the plaform, as the data would seem to indicate. Another explanation could be that the popularity score is not calculated by spotify before some criteria is met, e.g. a track has been on the planform for period of time. It depends on how and when the score is computed, when the tracks were put on the platform, all information that the group does not currently have.</p>
<h3 id="popularity-distribution-by-genre">Popularity distribution by Genre</h3>
<pre class="hljs"><code><div>Genres = spotifyDBData[<span class="hljs-string">'genre'</span>] <span class="hljs-comment"># Series containing genres of each track</span>
UniqueGenres = Genres.unique()  <span class="hljs-comment"># Contains the name of each genre included in DB</span>

cols = <span class="hljs-number">4</span>   <span class="hljs-comment"># How many subplots pr row</span>
width = <span class="hljs-number">15</span> <span class="hljs-comment"># Width of figure</span>
prop = <span class="hljs-number">1</span>/<span class="hljs-number">3</span> <span class="hljs-comment"># Subplot proportions, width/height ratio of subfigures</span>

rows = int(len(UniqueGenres)/cols)+<span class="hljs-number">1</span>
height = (rows/cols)*width*prop

fig, ax = plt.subplots(rows, cols, figsize=(width,height))
plt.subplots_adjust(wspace=<span class="hljs-number">0.2</span>, hspace=<span class="hljs-number">1</span>)
<span class="hljs-keyword">for</span> index, genre <span class="hljs-keyword">in</span> enumerate(UniqueGenres):
    row, col = int(index/cols), index % cols
    genre_tracks = spotifyDBData.loc[spotifyDBData[<span class="hljs-string">'genre'</span>] == genre]
    popularity = genre_tracks[<span class="hljs-string">'popularity'</span>]
    title = genre + <span class="hljs-string">", N = "</span> + str(len(popularity))
    ax[row,col].hist(popularity, bins=<span class="hljs-number">40</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">'Track Popularity'</span>)
    ax[row,col].set_title(title)
</div></code></pre>
<p>This produces the following output:</p>
<figure class="image">
    <img src=fig/popularity_pr_genre.png>
    <figcaption> <center> Popularity histograms for each genre</figcaption> 
</figure>
<p>Here it can be seen that the spike in the first bin is only present in a few of the genres, &quot;A Capella&quot;, &quot;Movie&quot;, &quot;Children's Music&quot; and &quot;Classical&quot;.</p>
<h3 id="genre-pre-processing">Genre Pre-processing</h3>
<p>The genre feature is a text string in the original dataset, but in order to be more useful to a machine learning algorithm, numerical values must be assigned through some form of preprocessing. As the unprocessed genre feature contains one of 18 possible textstrings with the name of the gerne, one-hot encoding seems suitable in this case. This is done with pandas function <code>get_dummies</code>:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Apply One Hot Encoding to the genre feature</span>
onehotenc = pd.get_dummies(spotifyDBData, columns=[<span class="hljs-string">"genre"</span>])

<span class="hljs-comment"># Rename/format genre column (lowercase, no special symbols)</span>
replacements = {<span class="hljs-string">' '</span>:<span class="hljs-string">'-'</span>, <span class="hljs-string">'&amp;'</span>:<span class="hljs-string">'n'</span>, <span class="hljs-string">'’'</span>:<span class="hljs-string">''</span>}
onehotenc.columns = map(<span class="hljs-keyword">lambda</span> s: s.lower().translate(str.maketrans(replacements)), onehotenc.columns)

print(list(onehotenc.columns)) <span class="hljs-comment"># Check column names</span>
</div></code></pre>
<p>Which outputs the following</p>
<pre class="hljs"><code><div>['artist_name', 'track_name', 'track_id', 'popularity', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence', 'genre_a-capella', 'genre_alternative', 'genre_anime', 'genre_blues', 'genre_childrens-music', 'genre_classical', 'genre_comedy', 'genre_country', 'genre_dance', 'genre_electronic', 'genre_folk', 'genre_hip-hop', 'genre_indie', 'genre_jazz', 'genre_movie', 'genre_opera', 'genre_pop', 'genre_rnb', 'genre_rap', 'genre_reggae', 'genre_reggaeton', 'genre_rock', 'genre_ska', 'genre_soul', 'genre_soundtrack', 'genre_world']
</div></code></pre>
<p>It is seen that the genre column has been replaced with distinct culumns, one pr possible genre. If a track belongs to a genre, it has a value of 1 in its column, and 0 in the other genres.</p>
<p>This structure is also useful for predicting the genre, as each value between 0 and 1 can represent an algorithm's confidence that a track belongs to a certain genre.</p>
<h3 id="scaling">Scaling</h3>
<p>Numerical features can be scaled, so that they are always between 0 and 1.
The code below scales a selection of numerical features in such a way by using scikit learns <code>MinMaxScaler</code></p>
<pre class="hljs"><code><div>genres = list(filter(<span class="hljs-keyword">lambda</span> name: <span class="hljs-string">"genre_"</span> <span class="hljs-keyword">in</span> name, onehotenc.columns))
audiofeature_cols = [<span class="hljs-string">'popularity'</span>, <span class="hljs-string">'acousticness'</span>, <span class="hljs-string">'danceability'</span>, <span class="hljs-string">'energy'</span>, 
                 <span class="hljs-string">'instrumentalness'</span>, <span class="hljs-string">'liveness'</span>, <span class="hljs-string">'loudness'</span>, <span class="hljs-string">'speechiness'</span>, 
                 <span class="hljs-string">'tempo'</span>, <span class="hljs-string">'valence'</span>]       

minmaxscaler = MinMaxScaler()

df_scaled = pd.DataFrame(onehotenc)
df_scaled[audiofeature_cols] = pd.DataFrame(
        minmaxscaler.fit_transform(df_scaled[audiofeature_cols]), 
        index=df_scaled[audiofeature_cols].index,
        columns=df_scaled[audiofeature_cols].columns)

</div></code></pre>
<h3 id="audio-features-by-genre">Audio Features by genre</h3>
<p>To get an overview of how the different audiofeatures are distributed internally in each genre, a &quot;radar plot&quot; can be created for each genre, with the mean/average value of audiofeatures.</p>
<pre class="hljs"><code><div><span class="hljs-comment">#Extract audiofeatures from a tracks of a specific genre</span>
tracks = {genre: df_scaled.loc[df_scaled[genre] == <span class="hljs-number">1</span>]
                    .reset_index(drop=<span class="hljs-literal">True</span>)
                    .filter(audiofeature_cols)
            <span class="hljs-keyword">for</span> genre <span class="hljs-keyword">in</span> genres}

<span class="hljs-comment"># Mean and median</span>
afeatures_mean = {genre: tracks[genre].mean().values.flatten().tolist()
                  <span class="hljs-keyword">for</span> genre <span class="hljs-keyword">in</span> genres}
afeatures_median = {genre: tracks[genre].median().values.flatten().tolist()
                    <span class="hljs-keyword">for</span> genre <span class="hljs-keyword">in</span> genres}

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">radar_subplot</span><span class="hljs-params">(categories, data, title=None, subplotpos=<span class="hljs-params">(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)</span>)</span>:</span>
    <span class="hljs-comment"># Dimension angles</span>
    N = len(categories)
    angles = [n / float(N) * <span class="hljs-number">2</span> * math.pi <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> range(N)]
    
    <span class="hljs-comment"># Create polar subplot</span>
    ax = plt.subplot(subplotpos[<span class="hljs-number">0</span>],subplotpos[<span class="hljs-number">1</span>],subplotpos[<span class="hljs-number">2</span>], polar=<span class="hljs-literal">True</span>)
    ax.set_rlabel_position(<span class="hljs-number">0</span>)
    ax.set_title(title)
    plt.xticks(angles, categories, color=<span class="hljs-string">'grey'</span>, size=<span class="hljs-number">10</span>)
    plt.yticks([<span class="hljs-number">0.2</span>,<span class="hljs-number">0.4</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">0.8</span>], [<span class="hljs-string">"0.2"</span>,<span class="hljs-string">"0.4"</span>,<span class="hljs-string">"0.6"</span>,<span class="hljs-string">"0.8"</span>], color=<span class="hljs-string">"grey"</span>, size=<span class="hljs-number">10</span>)
    plt.ylim(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)
    
    <span class="hljs-comment"># Plot one line/shape pr item in data</span>
    plotdata = data <span class="hljs-keyword">if</span> isinstance(data[<span class="hljs-number">0</span>],list) <span class="hljs-keyword">else</span> [data]
    angles += angles[:<span class="hljs-number">1</span>]
    <span class="hljs-keyword">for</span> values <span class="hljs-keyword">in</span> plotdata:
        plotvalues = values + values[:<span class="hljs-number">1</span>]  <span class="hljs-comment"># Line finishes same place as it starts</span>
        ax.plot(angles, plotvalues, linewidth=<span class="hljs-number">1</span>, linestyle=<span class="hljs-string">'solid'</span>)
        ax.fill(angles, plotvalues, <span class="hljs-string">'b'</span>, alpha=<span class="hljs-number">0.1</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_audiofeatures</span><span class="hljs-params">(genres, cols=<span class="hljs-number">3</span>, width=<span class="hljs-number">18</span>, hspace=<span class="hljs-number">0.3</span>)</span>:</span>
    rows = int(len(genres)/cols)+<span class="hljs-number">1</span>
    height = width*(rows/cols)    
    plt.figure(figsize=(width,height))
    plt.subplots_adjust(hspace=hspace)
    <span class="hljs-keyword">for</span> idx, genre <span class="hljs-keyword">in</span> enumerate(genres):
        genre = genre <span class="hljs-keyword">if</span> genre.startswith(<span class="hljs-string">"genre_"</span>) <span class="hljs-keyword">else</span> <span class="hljs-string">"genre_"</span> + genre
        categories = list(tracks[genre])
        subplot = (rows, cols, idx+<span class="hljs-number">1</span>)
        layers = [afeatures_mean[genre], afeatures_median[genre]]
        title = genre.replace(<span class="hljs-string">"genre_"</span>,<span class="hljs-string">""</span>).capitalize()
        radar_subplot(categories, layers, title, subplot)
        
plot_audiofeatures([<span class="hljs-string">"blues"</span>, <span class="hljs-string">"classical"</span>, <span class="hljs-string">"comedy"</span>, <span class="hljs-string">"country"</span>, <span class="hljs-string">"electronic"</span>, 
                    <span class="hljs-string">"folk"</span>, <span class="hljs-string">"jazz"</span>, <span class="hljs-string">"opera"</span>, <span class="hljs-string">"rap"</span>, <span class="hljs-string">"rock"</span>, <span class="hljs-string">"reggae"</span>, <span class="hljs-string">"soul"</span>])
</div></code></pre>
<p>Executing the above code, results in the following output:</p>
<figure class="image">
    <img src=fig/genre_radar.png>
    <figcaption> <center> Mean and average values audiofeatures for 12 genres</figcaption> 
</figure>
<h3 id="correlation-between-audio-features">Correlation between audio-features</h3>
<p>To investigate any relation/correlation between the audiofeature, a scatter matrix can be made</p>
<pre class="hljs"><code><div>attributes = [<span class="hljs-string">"tempo"</span>, <span class="hljs-string">"popularity"</span>, <span class="hljs-string">"acousticness"</span>, <span class="hljs-string">"danceability"</span>, <span class="hljs-string">"energy"</span>]
axs = scatter_matrix(onehotenc[attributes], figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">20</span>), alpha=<span class="hljs-number">0.01</span>)
</div></code></pre>
<figure class="image">
    <img src=fig/correlation_scatter_matrix.png>
    <figcaption> <center> Scatter matrix for 6 audiofeatures</figcaption> 
</figure>
<p>No single feature seems to be good for directly predicing another with any accuracy. Some slight correlation can be observed, for instance what looks like a negative correlation between &quot;acousticness&quot; and &quot;energy&quot;.</p>
<p>But especially for the audiofeatures, it is perhaps not surprising that the audiofeatures aren't strongly correlated, as one could imagine that they were engineered in the first place to describe different aspects of a song.</p>

</body>
</html>
